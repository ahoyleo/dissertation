\section{Discussion}
\label{sec:discussion}

Our results demonstrate the power of domain knowledge in data mining. Using the proposed combined RDF bipartite graph for both data and ontology, the incorporation of domain knowledge can be achieved by simply encoding it in the ontology and weighting appropriately relevant parts of the ontology that best suits the mining task. In the following, we summarize some assumptions and limitations of
the current study. And we also outline some directions for future work. 

\subsection{Scalability Issues}

The presented graph-based semantic mining framework heavily relies on the notion of graph-based similarity. We describe the use of several random walk-based measures. The calculation of eigenvectors of the Laplacian is required to derive the similarity measures and is very expensive on large graphs. Non-trivial practical problems are often associated with large scales. For example, in our experiment, the full Healthcare dataset contains 100 billion triples, and the size of ontology is also huge (SNOMED-CT is xxx terms in size). The proposed method is able to produce query-based node similarity but will not scale to generate full pair-wise node similarities which are useful in many mining tasks. Therefore developing scalable algorithms for the graph-based semantic mining methods are of critical importance.

The general solution to is to employ approximation and develop parallelizable algorithms. Lin and Cohen~\cite{LinEtal2010ICML} proposed an approximation to a eigenvalue-weighted linear combination of all the eigenvectors, which can be achieved by performing a small number of matrix-vector multiplications.  Such procedure results in a simple and scalable method called power iteration clustering that finds a very low-dimensional data embedding using truncated power iteration on a normalized pair-wise similarity matrix of the data points. Zhao \etal~\cite{ZhaoEtal2011Eff} described the idea of graph coordinate systems, which embeds graph nodes into points on a coordinate system. By allowing lower distance distortion errors, they were able to develop a practical system that provides fast embedding of large graphs in a hyperbolic space. The embedding algorithm can be parallelized to allow the cost of embedding process being spread across multiple servers. Furthermore, they presented a method to use graph coordinates to efficiently locate shortest paths between node pairs. Such concept can be naturally extended to embed graph nodes according to their commute time distance. Savas and Dhillon~\cite{SavasEtal2011Clu} introduced a novel framework called clustered low rank matrix approximation for massive graphs. The first step is to partition the vertices into a set of disjoint clusters with some fast procedure to preserve important structural information of the original graph. Then a low rank approximation of each cluster is computed independently. Finally the different cluster-wise approximations are combined using an optimal projection step to obtain a low rank approximation of the entire graph, thus including connections or edges between vertices from different clusters. While all these techniques are promising, we will need to extend and them to the RDF bipartite graph and stratification (between data and ontologies and among different semantic types) of the graph may require further adaptions and modifications to those algorithms.

\subsection{Learning Weights Automatically}
The RDF bipartite graph representation relies on the assignment of weights to different types of hyperedges to distinguish the underlying semantics they represent. In reality, the appropriate ratio for the edge weights is not only dependent on the size of graphs but also the graph configuration (depth, average degree, etc). Moreover, specifying the ratio of prior knowledge in ontologies and inductive evidences in data that one wants to employ for discovering new patterns is a highly empirical process. Multiple pilot trials may need to be carried out for the optimal ratio before it is applied to the real application. However such process is tedious and the difficulty is especially noticeable when there are multiple semantic relationships present in the data and ontologies that one hopes to distinguish so as to achieve finer-grained control over their respective contributions to the mining result. Therefore how to automatically derive suitable weights is an important research question.

One technique that can be used is to train a prediction model from labeled data. This approach suffers from the difficulty to acquire the gold-standard training sample. Tian \etal~\cite{Tian2009AHyper} proposed an semi-supervised approach for classifying nodes in a graph based on a relatively small labeled set. The main idea is to formalize the weight assignment and label propagation in one constraint optimization problem while the two objectives can be alternately solved using a two-step iterative method. While this approach is promising, how to extend it to other mining tasks such frequent pattern mining is still an open question.

\subsection{New Ways of Representing Complex Domain Semantics}
The RDF bipartite graph can represent concrete semantics such as the ``\emph{is\_a}" or ``\emph{located\_in}" relationship. However meta semantics such as domain/range and cardinality constraints are not so straightforward to be modeled.

One possible approach that can be used to enhance the ability of handling more complex domain semantics in certain applications is to model domain constraints by explicitly describing the desired or acceptable walk (traversal sequence) in the RDF hypergraph. In this case, the recently proposed regular traversal expression ~\cite{Marko10} is worth investigation. In the basic case, we can specify only certain types of nodes in a given random walk. The regular traversal expression can allow us to even specify acceptable path segments or sequences. However, the fast power-iteration approach for computing the stationary probability may not be applicable any more due to the label sequence constraint. To address this problem, we can apply the Monte-Carlo simulation of the random walk to approximate the similarity measure. Note that this approach can be rather scalable as the simulation can be in general constrained in those nodes linking two targeted nodes.

\subsection{Other Applications of the RDF bipartite Graph}
We have showcased The utility of the RDF bipartite graph in mining semantic associations. It is worth noting that such formalism is flexible and can be readily extended to solve other data mining tasks such as clustering and classification. For example, in Figure~\ref{fig:bipartitegraph-weighted}, the leftmost partition corresponds to rows in the underlying relational table. Suppose a subset of vertices are labeled (\eg, $r_1$ is labeled $l_1$ and $r_4$ is labeled $l_2$), then the classification problem can be formulated as to discover correct labels for unlabeled vertices (\eg, $r_1$ and $r_3$). Conceptually, the pair of nodes being ``close to'' one another shall share the same labels, which are consistent to one basic principle of  semi-supervised learning. However, the challenge is how can we define the closeness between two nodes. We can still rely on the paths linking them where the path length becomes an important measure as well as the node labels. On the other hand, the clustering of rows of the underlying relational table can be viewed as a neighborhood formation for vertices on the leftmost partition. Basically, for any closely related nodes, we should group them together. Especially, if we can derive an explicit  similarity/distance measure, then classical distance-based clustering algorithms, such as k-means, can be directly applied to cluster the vertices.
