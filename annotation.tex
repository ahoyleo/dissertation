%Annotation in general (traditionally) is a summary made of information in some source such as document, online record, image, video and so forth. With the emergence and development of the Semantic Web, there have been increasing demands for \emph{semantic annotation}, a kind of meta-data derived based upon specific knowledge about the world, rather than indifferent to any ontological commitments. In other words, semantic annotation aims at assigning to the basic element of information links to formal semantic descriptions~\cite{KiryakovEtal04}. Such elements should constitute the semantics of their source, for example, named entities in a document, certain part of an image depicting someone's head portrait.

%Semantic annotation is crucial in realizing semantic data mining by bridging formal semantics in Semantic Web meta-data with data. The majority of data underpinning a wide spectrum of data mining applications are stored in various formats, including structured sources such as relational databases (RDB) with their proven track record of scalability and reliability, or semi-structured sources such as spreadsheets with their advantage of low maintenance and cheaper overheads, or even unstructured sources such as text corpus. The problem of how to impart knowledge encoded in Semantic Web ontologies to all sorts of data becomes a major challenge in realizing the semantic data mining. We believe \emph{semantic annotation} is the solution to this challenge. It aims at assigning semantic descriptions to elements of data. To ease the burden of common users that are not familiar with the Semantic Web, we develop a learning-based semantic search algorithm to suggest appropriate semantic descriptions for annotation.

%thesis-semantic-annotation-workflow


%The annotation process can be generally divided into two steps. The first is to establish mappings between existing Semantic Web terms and terms need to be annotated in the data. The second step is to come up with a local ontological structure constituting the semantic web terms to model the data.

%Most of previous work in annotating (semi-)structured data focus on the second step. Some skip the first step and bootstrap the ontological terms and structure from the local data itself. For example, a number of systems that map data in RDB to RDF format leverage a set of rules such as ``table to class and column to predicate". Bernes-Lee expands the rule as follows~\cite{TBL98}: 1) An RDB record is a RDF node. 2) The column name of an RDB table is an RDF predicate. And 3) An RDB table cell is a value. Other examples of rules involved in mapping RDB schema to OWL ontology include ``foreign keys to object property and non-key attributes to datatype property".
%Similar idea has been adopted in annotating spreadsheets as well. Existing spreadsheet-to-rdf tools typically map spreadsheets to star-shaped RDF graphs, i.e., each row is an instance, with each column representing a property. Some tools try to express richer spreadsheet semantics, e.g., Han et al. developed a spreadsheet-to-rdf tool called RDF123~\cite{RDF123} that allows users to define mappings to arbitrary graphs.

%We argue that mapping RDB or spreadsheet to linked data (e.g., RDF) without referencing to existing semantic descriptions does not lend itself well to aiding semantic data mining. The automatically constructed self-contained local ontology may be applicable to describe a specific dataset but is most likely too rough to capture the full domain semantics that is necessary to express meaningful domain knowledge. Moreover, with the advent of the Semantic Web and pervasive connectivity, an increasing number of ontologies has been made widely available for reuse. These ontologies are created by thorough knowledge engineering process and should serve as better models for annotation. However, on the other hand, the sheer number of Semantic Web ontologies and lack of effective search functionality can lead to a huge hidden barrier for common users. Choosing proper Semantic Web ontologies and terms (classes and properties) requires familiarity with appropriate ontologies and the terms they define. There is very few system that is able to provide automatic suggestions. To solve this problem, we propose a learning-based semantic search algorithm to suggest proper Semantic Web terms and ontologies for annotation given semantically related words and general domain and context information.

%In order to suggest suitable Semantic Web terms and ontologies for users to annotate their data, we propose a learning-based semantic search algorithm. We first submit a list of terms appeared in the schema of (semi-)structured data to our semantic search algorithm and then use the returned results for annotation. In a fully automatic setting, the search algorithm is configured to return the top-1 hit; while in an interactive setting, the search algorithm returns ordered top-k search results for users to decide. Previous semantic search algorithms leverage a variety of measures, including lexical and structural similarities (see details below) to rank Semantic Web documents according to how likely they can be semantically matched to the search terms. However, using any single measure alone may not be sufficient to achieve the optimal result. We propose to combine various measures to a weighted feature-based search model, where the weights are learned from training data. We believe the incorporation of learning techniques will improve the semantic search result. We have built a prototypical system for gathering training data for two algorithms: logistic regression and subgradient descent. The evaluation of such method is a matter of ongoing research.


%%general review of the field of ontology matching
We have described the method to model data and domain knowledge encoded in ontologies in a unified graph representation. In practice, it is common that raw data reside in disparate sources and alternative ontologies or schemas are present in a domain. When a data mining system is required to access multiple sources of information, how to resolve heterogeneities is a challenging task. This chapter makes a contribution in this direction.

\section{Overview}
The presence of heterogeneity among schemas supporting vast amounts of information demands an advanced solution for semantic integration of disparate data sources to facilitate interoperability and reuse of the information. The challenge is especially pronounced in many scientific domains where a massive amount of data is produced independently and thus each has its own data vocabulary. While manual integration is time-consuming and requires expensive specialized human capital, the development of automatic approaches becomes essential to aid inter-institute collaborations.

In our attempt to tackle the problem, we focus on developing a method to solve a specific kind of integration problem involving matching alternative ontologies or schemas. We recognize several key constraints that make our problem challenging and can cause conventional methods to be ineffective. They are, namely, 1) little-to-no string-based or linguistic similarity between vocabularies, and 2) numeric typed data instances. The discovery of matching between numeric-typed attributes used in different datasets is a common task in integrating scientific datasets that have been collected and analyzed in different research labs. We call such task the \emph{attribute matching} problem.

Another challenging task given multiple data sources is to carry out meaningful meta-analysis that combines results of several studies on different datasets to address a set of related research hypotheses. Finding correspondences among distinct patterns that are observed in different scientific datasets is an example of meta-analysis. Supposing the patterns are derived by clustering analysis, this problem can be addressed by the application of cluster comparison (or cluster matching) techniques. Clustering is an unsupervised data mining task widely used to discover patterns and relationships in a variety of fields. The clustering result provides a pattern characterization from a data-driven perspective. If similar results are obtained across multiple datasets, this leads in turn to a revision and refinement of existing domain knowledge, which is a central goal of meta-analysis. However, there are noticeably few cluster comparison methods that are able to compare two clusterings derived from different datasets. The difficulty for the comparison is further exacerbated by the fact that the datasets may be described by attributes from heterogeneous schemas or ontologies. Even those methods that are able to measure clustering similarity across different datasets (e.g., the ADCO~\cite{Bae2010} method) have to assume homogeneous meta-data (e.g., the same schemas).

Given this situation, in order to carry out cluster comparison for meta-analysis, researchers often need to perform ontology or schema matching first in order to mitigate the gap for meta-data. In the work reported in~\cite{LiuEtal10}, we examine a practical attribute matching problem on neuroscience data where schema elements from one dataset share no lexical similarity with those from the other. Moreover, structural similarity is also limited. One can only resort to instance-based (extensional) methods. However, since all attributes are numerical, information clues available to an instance-level matcher are very restricted. Traditional instance-based matchers typically make use of constraint-based characterization, such as numerical value ranges and averages to determine correspondences. However, this is often too rough in the case of an all-numerical dataset. Two attributes may have similar ranges and averages but totally different internal value distributions (an example is shown in Section~\ref{sec:syn_exp}). Given this, we propose to represent the attribute value distribution at a finer granularity by partitioning the values into groups. To do this, clustering is performed, and the resulting clusters are then aligned across two datasets (assuming that the same pattern exists in both datasets). In this way, each attribute can be characterized by, instead of a single value, a vector of per-cluster statistical quantities (which we also call the \emph{segmented statistical characterization}). A distance function can then be applied based on this representation. Table~\ref{tbl:sim_mat}(A) shows an example distance table on the cross join of two sets of attributes. To discover attribute matching from this table can be reduced to solving a minimum assignment problem (assuming matching is bijective), which is a classical combinatory optimization problem that has a polynomial solution using the Hungarian Method~\cite{Kuhn1955}.

Unfortunately, however, the above solution requires the alignment of clusters across datasets, which is a difficult problem in its own right. If fully automated, as mentioned above, methods such as ADCO adopt a so called \emph{density profile}~\cite{Bae2010} representation of clusters that requires homogeneous meta-data or a priori knowledge about the attribute matching in heterogeneous scenarios. Then the cluster matching can be carried out in a similar manner to the attribute matching by being solved as an assignment problem (see Table~\ref{tbl:sim_mat}(B), for example). This leads to a circular causality, or a deadlock, between the attribute matching (under the segmented statistical characterization) and cluster matching (under the density profile representation) --- none of them can be solved automatically without the other one being solved first.


\begin{table}
\begin{center}
\begin{minipage}{0.45\linewidth}\centering
\begin{tabular}{c | c c c}
	& \textbf{$a'_1$}		& $\cdots$ & \textbf{$a'_m$}\\
\hline
\textbf{$a_1$}	& $d_{11'}$ & $\cdots$  & $d_{1m'}$\\
%\textbf{$a_2$}	& $d_{21'}$	&           & $d_{2m'}$\\
$\vdots$        &           & $\ddots$  &\\
\textbf{$a_m$}	& $d_{m1'}$	&           & $d_{mm'}$\\
\multicolumn{4}{c}{(A)}\\
\end{tabular}
\end{minipage}
\hspace{.5cm}
\begin{minipage}{0.45\linewidth}\centering
\begin{tabular}{c | c c c c}
	& \textbf{$c'_1$}	& $\cdots$ & \textbf{$c'_n$}\\
\hline
\textbf{$c_1$}	& $d_{11'}$ & $\cdots$  & $d_{1n'}$\\
%\textbf{$c_2$}	& $d_{21'}$	&           & $d_{2n'}$\\
$\vdots$        &           & $\ddots$  &\\
\textbf{$c_n$}	& $d_{n1'}$	&           & $d_{nn'}$\\
\multicolumn{4}{c}{(B)}\\
\end{tabular}
\end{minipage}
\end{center}
\caption[Example distance matrices]{\label{tbl:sim_mat} Example distance matrices between (A) two sets of attributes and (B) two sets of clusters, respectively.}
\end{table}

To address this difficulty, viewing the two matching problems as combinatorial optimization problems with distinct yet interrelated objective functions, we propose a novel approach using a multi-objective heuristics to discover attribute matching and cluster matching simultaneously. The objectives in the optimization are to minimize distances of attribute matching and cluster matching respectively. We explore the widely used simulated annealing algorithm as the metaheuristics algorithm and briefly compare its performance with the evolutionary multi-objective algorithm in experiments.

\section{Method}
\textbf{Problem Definition:} We tackle two matching tasks in this work, namely, the attribute matching and cluster matching problems. The solution is to cast the dual matching problems to a multi-objective optimization problem so that the matchings can be solved simultaneously. The two objective functions to be optimized are defined as the total distance of corresponding elements in attribute and cluster matching respectively. To this end, we explore methods to represent attributes and clusters so that distance measure can be reasonably defined. We assume that the optimal matching lies at the Pareto front in this multi-objective problem.

We use metaheuristics search algorithm to solve this multi-objective optimization problem. In the following we describe an adaption of the widely used simulated annealing algorithm to multi-objective optimization in order to solve the matching problems. Later in the Experiment Section, we briefly describe an evolutionary multi-objective algorithm and compare their performance.

\subsection{The Multi-Objective Simulated Annealing Framework}
Simulated annealing (SA) is a generic probabilistic metaheuristic for the global optimization problem of locating a good approximation to the global optimum of a given function in a large search space. We briefly describe SA in Section~\ref{metaheuristics}, Chapter~\ref{chap:background}. To solve the dual matching problems, we adopt an adaptation of SA for multi-objective optimization. The resulting algorithm is the so-called multi-objective simulated annealing (MOSA~\cite{Suman2003}), in which the acceptance criterion in the annealing process is established based on the idea of Pareto-domination based fitness. Specifically, fitness of a solution is defined as one plus the number of dominating solutions in Pareto-optimal set. The larger the value of fitness, the worse is the solution. Initially, the fitness difference between the current and the generated solution is small and the temperature is high so almost any move is accepted. This gives a way for the search to explore as much of the solution space as possible. As the number of iterations increases, temperature decreases and the fitness difference between the current and generated solutions may increase. Both of them make the acceptance more selective and can result in a well-diversified set of Pareto-optimal solutions. Details of the multi-objective simulated annealing algorithm are outlined in Algorithm~\ref{MOSA}.


%\subsection{Simulated Annealing}
\begin{algorithm}
\caption{Multi-Objective Simulated Annealing}
\label{MOSA}
\begin{algorithmic}
\REQUIRE Empty Pareto-optimal set of solutions $\mathbf{\Sigma}$
\REQUIRE Empty current decision vector $\mathbf{X}=[x_a,x_c]$
\REQUIRE Initial temperature $T$
\STATE $count=0$
\WHILE{$T > threshold$}
\STATE $initialize(\mathbf{X})$ \hspace{1in} %$//\mathbf{X}^0=[x_a^0,x_c^0]$
\STATE If $\mathbf{X}$ is pareto-optimal, put $\mathbf{X}$ in $\mathbf{\Sigma}$
\STATE $\mathbf{X}'=generate\_solution(\mathbf{X})$
\STATE $S_{\mathbf{X}'}=evaluate\_solution(\mathbf{X}')$
\STATE $\Delta S = S_{\mathbf{X}'} - S_X$
\IF{$r=rand(0,1)<exp(\frac{-\Delta S}{T})$}
\STATE $\mathbf{X}=\mathbf{X}'$
\STATE $S_X=S_{X'}$
\ENDIF\\
\STATE count = count + 1
\STATE //Periodically restart
\IF{$count == restart\_limit$}
\STATE $\mathbf{X}=select\_random\_from\_Pareto(\mathbf{\Sigma})$
\STATE continue
\ENDIF
\STATE $reduce\_temperature(T)$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

Formally, the processes involved in the proposed multi-objective simulated annealing framework can be defined as follows.
\begin{align}
\notag X&=[x_a, x_c]\\
\notag F&=[f_a, f_c]\\
\notag P_a([x_a^{(n-1)},x_c^{(n-1)}])&=[x_a^{(n)}, x_c^{(n-1)}]\\
\notag P_c([x_a^{(n-1)},x_c^{(n-1)}])&=[x_a^{(n-1)}, x_c^{(n)}]\\
\notag G_{c|a}([x_a^{(n)},x_c^{(n-1)}])&=[x_a^{(n)}, x_c^{(n)}]\\
\notag G_{a|c}([x_a^{(n-1)},x_c^{(n)}])&=[x_a^{(n)}, x_c^{(n)}]\\
\notag G\circ P([x_a^{(n-1)},x_c^{(n-1)}])&=[x_a^{(n)}, x_c^{(n)}]
%F(X^{(n)})&=[f_a(x_a^{(n)}), f_c(x_c^{(n)})]
\end{align}
$X$ is the decision vector that contains two variables for attribute matching, $x_a$, and cluster matching, $x_c$, respectively (details in Section~\ref{sec:variables}). $F$ is the objective function vector that contains two criterion functions ($f_a$ and $f_c$) to evaluate attribute matching and cluster matching decisions (details in Section~\ref{sec:obj_funcs}). $P$ is the random perturbation function that takes a decision vector in the $(n-1)$th iteration and partially advances it to the $n$th iteration (we use $P_a$ or $P_c$ to distinguish between the random selections). The partial candidate decision generation function $G$ takes the output of $P$ and fully generate a decision vector for the $n$th iteration (by advancing the left-out variable in $P$ to its $n$th iteration). Thus, the compound function $G\circ P$ fulfils the task of generating an $n$th-iteration candidate decision vector given the $(n-1)$th one (details in Section~\ref{sec:new_sols}).
\subsection{Decision Variable}
\label{sec:variables}
The domains of the decision variables in the matching problems take values on a permutation space. In other word, by formalizing the problem of finding correspondent elements of two sets $S$ and $S'$ of cardinality $n$ as an optimization problem, the solution is completely specified by determining an optimal permutation of ${1,\ldots,n}$. For instance, for two sets of three elements, their indexes range over $\{0, 1, 2\}$. Applying a permutation $\pi =\{2, 0, 1\} \in S_3$ on $S'$ can be viewed as creating a mapping (bijection) from elements on the new positions of $S'$ to elements on the corresponding positions in $S$. %This mapping underlies the correspondence we try to discover in the matching problem.
In this example, the permutation $\pi$ on $S'$ specifies the following correspondences: $S_0 \leftrightarrow S'_2$, $S_1 \leftrightarrow S'_0$, and $S_2 \leftrightarrow S'_1$.

Formally, let $P_n$ ($n\in \mathbb{N}$) be the symmetric group of all permutations of the set $\{1, 2, \ldots, n\}$. Given two sets $S$ and $S'$ with the same cardinality of $n$, performing identity permutation on one set and an arbitrary permutation $\pi \in S_n$ on the other specifies a matching (or mathematically speaking, mapping) between the two sets.
In the multi-objective optimization formalism for solving the attribute matching and cluster matching problems, the decision vector has two variables: $X=[x_a, x_c]$. If we have $M$ attributes and $N$ clusters to match respectively, then $x_a \in P_M$ and $x_c\in P_N$.

%Let us first define $\rho$ as the stochastic permutation of a subscript index set. Without causing confusion, we also define function $\rho(k)$ that returns the value at index $k$ in the permutation set. (i.e., $\rho = \{\rho(1), \rho(2), ... \rho(n)\}$ is the permutation of $\{0, 1, ..., n\}$.) We can view $\rho$ as a correspondence function between set $S_k$ and $S'_{\rho(k)}$, assuming correspondent positions in each set are considered to map to each other. For instance, if two sets both have three elements, then the subscript index set ranges over $\{0, 1, 2\}$. Supposing $\rho$ returns $\{2, 0, 1\}$, we can then obtain following matchings: $S_0 \leftrightarrow S'_2$, $S_1 \leftrightarrow S'_0$, and $S_2 \leftrightarrow S'_1$.

\subsection{Data Representation}
The central objects of interest in our study, namely, the numeric-typed attributes and clusters, need to be represented in ways that meaningful quantities can be defined to measure the ``goodness" of a matching decision. To this end, we propose to use the \emph{segmented statistical characterization} to represent attributes, and the \emph{density profiles} to represent clusters. Details of these representations are described below.
\subsubsection{Representation of Attributes:}
Numeric-typed attributes can be represented by the segmented statistical characterization, in which data instances are first partitioned into groups (e.g., through unsupervised clustering) and then characterized by a vector of indicators, each denoting a statistical characterization of the corresponding group. For example, if values of an attribute $A$ are clustered into $n$ groups, then it can be represented by a vector of segmented statistical characterization as follows:
\[
V_A=\bigg[\mu_1, \mu_2, \ldots, \mu_n\bigg],
\]
where we choose the mean value $\mu_i$ for cluster $i$ as the statistical indicator in our implementation.

\subsubsection{Representation of Clusters:}
Clusters can be represented by density profiles~\cite{Bae2010} as described in Section~\ref{sec:annotAndMatching}, Chapter~\ref{chap:background}. The attribute's range in each cluster is discretized into a number of bins, and the similarity between two clusters corresponds to the number of points of each cluster falling within these bins. Given this, density profile vector $V_C$ for a clustering $C$ is formally defined as an ordered tuple by~\ref{eq:densp}
%and is repeated here:
%\begin{align}
%\notag V_C = \bigg[ & dens_C(1, 1, 1), ~\ldots, ~dens_C (1, 1, Q),\\
%\notag & dens_C (1, 2, 1), ~\ldots, ~dens_C (1, M, Q),\\
%\notag & dens_C (2, 1, 1), ~\ldots, ~dens_C (N, M, Q) \bigg]\, ,
%\end{align}
%where $Q$ is the number of bins in each of the $M$ attributes, $N$ is the number of clusters in $C$, and
where $dens_C(k, i, j)$ refers to the number of points in the region $(i, j)$---the $j$-th bin of the $i$-th attribute---that belongs to the cluster $c_k$ of clustering $C$.
%The values of $dens_C(k, i, j)$ for all possible $k$, $i$, $j$ are then listed in a certain ordering to form a clustering's \emph{density profile vector} (defined below). This ordering is imposed on all attribute-bin regions and must be applied to the two datasets in which the clusterings were generated. It is necessary, then, that both datasets must have the same attribute set. If this requirement does not stand, the matching between the sets must be specified in advance. Therefore, in order to apply the density profile method in the ERP pattern matching problem, we must first carry out measure matching. We further discuss the interdependence between pattern matching and metric matching in Section~\ref{sec:discuss}.

\subsection{Objective Functions}
\label{sec:obj_funcs}
The objective functions in the attribute matching and cluster matching problems are criteria to evaluate the ``goodness" of matchings. We use the sum of pair-wise distances between matched elements (see Table~\ref{tbl:sim_mat} for example) as the objective function. Given this, to determine the form of objective functions amounts to defining proper pair-wise distance measures for the attribute and cluster matching problems respectively, as detailed in the following.


\subsubsection{Distance function between two attributes}
The pairwise distance $\mathcal{L}$ between two attributes is defined as the Euclidean distance between their segmented statistical characterization vectors, and $f_a$ calculates the sum of pair-wise distances under the attribute matching specified by $x_a$:
\begin{align}
\notag f_a(x_a)&=\sum_{k=1}^M\mathcal{L}\bigg((V_a)^k,~(V_a')^{x_a(k)}\bigg)\\
&=\sum_{k=1}^M\sqrt{\sum_{i=1}^N\bigg(\mu^{k}_i-(\mu')^{x_a(k)}_i\bigg)^2} \label{eq:calc_L_mm} ~~ ,
%&=\sum_{k=1}^M\sqrt{\sum_{i=1}^N\bigg(\Big(\mu_k\Big)_i-\Big(\mu'_{x_a(k)}\Big)_i\bigg)^2} \label{eq:calc_L_mm} \, ,
\end{align}
where $x_a \in P_M$.

\subsubsection{Distance function between two clusters}

The ADCO similarity described in~\ref{eq:adco} of Section~\ref{sec:clusterMatching}, Chapter~\ref{chap:background}, can be transformed to a distance defined as follows~\cite{Bae2010}:
\begin{align}
D_{ADCO}(C,C')=\left\{\begin{array}{ll}
	   { 2-ADCO(C,C')} & { ~if~ C \neq C'}\\
	   { 0} & ~{ otherwise}
	   \end{array}\right.
\end{align}
We use $D_{ADCO}$ as the pair-wise distance between two clusters under the density profile representation, and $f_c$ calculates the sum of pair-wise distances under the cluster matching specified by $x_c$
\begin{align}
\notag &f_c(x_c)=\sum_{k=1}^N D_{ADCO} \bigg((V_c)^k,~(V_c')^{x_c(k)}\bigg)\\
\notag &=\sum_{k=1}^N\Bigg(2- \sum_{i=1}^M\sum_{j=1}^Q\bigg({\scriptstyle dens(k,i,j)\times dens(x_c(k),i,j)\bigg) \bigg/ }\\ &\max{\bigg[\sum_{i=1}^M\sum_{j=1}^Q {\scriptstyle dens(k,i,j)^2},\sum_{i=1}^M\sum_{j=1}^Q {\scriptstyle dens(x_c(k),i,j)^2}\bigg]}\Bigg) \label{eq:calc_L_mm} \, ,
\end{align}
where $x_c \in P_N$.

\subsection{Generation of New Solution}
In each iteration of the simulated annealing process, we randomly generate a candidate decision in the neighborhood of the last-iteration decision by applying two consecutive processes, namely, the random perturbation and the partial candidate decision generation, as described below.
\subsubsection{Random Perturbation:} In each iteration, we select at random one variable (either $x_a$ or $x_c$) in the decision vector and perturb it by randomly swapping two positions in the selected variable. This advances that variable from the ($n-$1)th iteration to the $n$th iteration. Then the following partial candidate generation process is carried out to bring the other variable also to the $n$th iteration.
\subsubsection{Partial candidate decision generation}
\label{sec:new_sols}
Given $x_c^{(n)}$, derive $x_a^{(n)}$:
\begin{align}
\notag x_a^n&=\stackbin[\pi]{}{\argmin}\,f_a(\pi,x_c^{(n)})\\
\notag &=\stackbin[\pi]{}{\argmin}\sum_{k=1}^M\mathcal{L}\bigg((V_a)^k,~(V_a')^{\pi(k)}\bigg)\\
&=\stackbin[\pi]{}{\argmin}\sum_{k=1}^M\sqrt{\sum_{i=1}^N\bigg(\mu^{k}_i-(\mu')^{\pi(k)}_{x_c^{(n)}(i)}\bigg)^2} \label{eq:gen_xa}
\end{align}
Given $x_a^{(n)}$, derive $x_c^{(n)}$:
\begin{align}
\notag &x_c^n=\stackbin[\pi]{}{\argmin}\,f_c(\pi,x_a^{(n)})\\
\notag &=\stackbin[\pi]{}{\argmin}\sum_{k=1}^N D_{ADCO}\bigg((V_c)^k,~(V_c')^{\pi(k)}\bigg)\\
\notag &=\stackbin[\pi]{}{\argmax}\sum_{k=1}^N\Bigg(\displaystyle \sum_{i=1}^M\sum_{j=1}^Q \bigg({\scriptstyle dens(k,i,j)\times dens(\pi(k),x_a^{(n)}(i),j)}\bigg) \bigg/\\
&\max{\bigg[\sum_{i=1}^M\sum_{j=1}^Q {\scriptstyle dens(k,i,j)^2},\sum_{i=1}^M\sum_{j=1}^Q {\scriptstyle dens(\pi(k),x_a^{(n)}(i),j)^2}\bigg]}\Bigg) \label{eq:gen_xc}
\end{align}

To calculate $\pi$ that satisfies~\ref{eq:gen_xa} and~\ref{eq:gen_xc}, rather than iterating through all possible permutations, we can consider the equation as a minimum-cost assignment problem. Table~\ref{tbl:sim_mat}(A), for example, illustrates a distance table between two attribute sets $A$ and $A'$. Matching of the two sets can be considered as an assignment problem where the goal is to find an assignment of elements in $\{A_i\}$ to those in $\{A_i'\}$ that yields the minimum total distance without assigning each $A_i$ more than once. This problem can be efficiently solved by the Hungarian Method in polynomial time of $O(K_{min}^3)$~\cite{Kuhn1955}. It is worth noticing that by formulating the problem as the assignment problem, we assume the matching between two sets to be a one-to-one function.

\section{Case Studies}
\label{sec:experiment}
Because we are interested in understanding the property of the Pareto front obtained by our method, we conducted a series of experiments to highlight tradeoffs of the objectives functions. First, to illustrate the proposed method is indeed capable of determining matchings between numeric-typed attributes and clusters, we synthesized a dataset simulating some extreme conditions under which previous methods are ineffective. Also, from the results obtained on the synthetic dataset, we empirically study tradeoffs between the two objective functions. Then, to evaluate the scalability of the method, we carry out a series of tests on a set of data with varied sizes. Finally, encouraged by these results, we applied our methods to actual neuroscience ERP (event-related potentials) data to highlight the applicability of our method to the neuroscience domain.

\subsection{Synthetic Dataset}
\label{sec:syn_exp}
\subsubsection{Data Generation:}

In the synthetic dataset, tables are generated in such a way that each attribute consists several Gaussians with distinct means and standard deviations, and for one attribute in the source table, there exists exactly one attribute in the target table whose Gaussians possess the same configuration (hence they match each other). However if the attribute is viewed as a single distribution, as is typical in previous methods, its mean and standard deviation would be indistinguishable from those of other attributes in the same table. For example, Figure~\ref{fig:syndata} illustrates the value distributions of three attributes ($a_1, a_2,$ and $a_3$) from one dataset and their corresponding counterparts ($a_1', a_2',$ and $a_3'$) from another.

\begin{figure*}[tbh]
\begin{center}
\begin{tabular}{ccc}
\includegraphics[scale=0.112]{fig/clusters.eps} &
\includegraphics[scale=0.112]{fig/clusters4.eps} &
\includegraphics[scale=0.112]{fig/clusters3.eps} \\
$a_1$ --- range: [-4.74, 4.74] & $a_3$ --- range: [-4.61, 4.61] & $a_2$ --- range: [-4.02, 4.02] \\
$\mu$: 0, $\sigma$:2.26 &$\mu$: 0, $\sigma$:2.30 & $\mu$: 0, $\sigma$:2.18 \\
\includegraphics[scale=0.112]{fig/clusters21.eps} &
\includegraphics[scale=0.112]{fig/clusters23.eps} &
\includegraphics[scale=0.112]{fig/clusters22.eps} \\
$a_1'$ --- range: [-5.72, 5.72] & $a_3'$ --- range: [-5.24, 5.24] & $a_2'$ --- range: [-4.25, 4.25] \\
$\mu$: 0, $\sigma$:2.20 & $\mu$: 0, $\sigma$:2.35 & $\mu$: 0, $\sigma$:2.15 \\
\end{tabular}
\end{center}
\caption[Distribution of the synthetic dataset.]{\label{fig:syndata} Scatter plots of data instances from three sample attributes in one synthetic dataset (upper frame) and those of their corresponding attributes from another (lower frame) are illustrated to show their respective value distributions.}
\end{figure*}

\subsubsection{Results:}
Figure~\ref{fig:syn_pareto} illustrates the Pareto front obtained from matching two synthetic datasets, each having 20 attributes and 5 clusters. Most notably, the gold standard results for both attribute matching and cluster matching are obtained from the left-most point on the Pareto front. In other words, given the decision variables ($X$) corresponding to that point, we obtained 100\% correct matching results. We further observed that in our subsequent tests on other synthetic datasets with varied number of attributes and clusters, the derived Pareto fronts all contain the gold standard result, and the point corresponding to the gold standard can always be found towards the minimum end of $f_a$. Given this, we propose the following method to reduce the Pareto-optimal set to a single point corresponding to the most favored choice ($X^*$) in the decision space. The idea is to find the decision with the minimum weighted sum of objective values in the obtained Pareto-optimal set, i.e., $X^*=\stackbin[X]{}{\argmin}~\big[\alpha f_a(X)+\beta f_c(X)\big]$, where $\alpha$ and $\beta$ are weights. We first conducted preliminary experiments to determine the best values for $\alpha$ and $\beta$ (0.8 and 0.2 respectively) and used them in all subsequent experiments. This method works markedly well on the synthetic datasets. For all the tests described in Table~\ref{tbl:scale}, 100\% correct results for both attribute and cluster matchings are obtained (hence we omit the precision in the table).

Notice that it is common in multi-objective optimization problems that a non-dominated set may be too large for decision makers to reasonably consider. However, it is shown in Figure~\ref{fig:syn_pareto} (as well as results from other experiments described in the following) that this is not the case using our method on datasets of representative sizes in attribute and clustering matching problems. The number of resulting Pareto optimal solutions is small enough to be presented to decision makers without the need of any means of reducing or organizing the non-dominated set. The reason why we use a straightforward weighted sum method to compute the most significant solution from Pareto front is because it empirically works well on our test cases. This step is not obliged because a decision maker can go over solutions in Pareto front and decide which one is the best.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=0.4\textwidth]{fig/syn_pareto.eps}
\end{center}
\caption[An example Pareto front result from the synthetic dataset]{\label{fig:syn_pareto} An example Pareto front obtained from matching two synthetic datasets with 20 attributes and 5 clusters.}
\end{figure}

\subsubsection{Running Time}
We systematically altered the number of attributes and clusters present in the data and conducted a series of tests to show the scalability of the proposed method. The running time under different configurations is reported in Table~\ref{tbl:scale}. The time is calculated by averaging over 5 runs of each test (on a 2.53GHz dual-core CPU with 4 gigabytes memory), each run having 1000 iterations in the simulated annealing process. 

\begin{table}[tbh]
\begin{center}
\begin{tabular}{r|r|r}
\hline
\# attributes & \# clusters & time (sec)\\
\hline
5   &   20  &   0.28\\
20  &   20  &   1.81\\
20  &   40  &   7.04\\
20  &   60  &   17.80\\
40  &   20  &   4.66\\
40  &   40  &   11.74\\
40  &   60  &   25.93\\
60  &   20  &   10.95\\
60  &   40  &   20.70\\
60  &   60  &   37.35\\
100 &   100 &   172.23\\
\hline
\end{tabular}
\end{center}
\caption[Running time on the synthetic dataset]{\label{tbl:scale} Running time of the annealing process on synthetic datasets with varied configurations of attribute and cluster sizes. The time is obtained by averaging over results of 5 runs of each test.}
\end{table}


The main computationally expensive part of the annealing process is the generation of new candidate solution phase (function $G$) in which an assignment problem is solved using the Hungarian method. The complexity of the Hungarian method is cubic and is already the most efficient algorithm for solving the assignment problem (e.g., a brute force algorithm has a factorial complexity). In scenarios where the size of the problem is huge (both the number of attributes and the number of clusters are large), our method can become computationally costly. For example, the ARCENE dataset~\cite{ARCENE} from the UCI machine learning repository contains mass-spectrometric output with 10,000 continuous input variables. ARCENE's task is to distinguish cancer versus normal patterns and the dataset is typically used as a benchmark for classification and feature selection algorithms. To match sets of attributes at this scale will definitely require more advanced adaptation of our metaheuristics search algorithm, such as approximation or partitioning of the search space to enable parallelism. On the other hand, as we have shown in the synthetic test case and will elaborate upon in latter studies, our method boasts significant accuracy and the unique ability to distinguish attributes with similar statistics.  For the ARCENE dataset, we create an artificial matching problem by first randomly selecting a subset of data with 150 attributes as the source, and then make a target dataset by injecting a small amount of noise to the source. We then run the simulated annealing algorithm to find both attribute and cluster matchings and achieved 132/150 accuracy for attribute matching and 4/5 accuracy for cluster matching. A baseline method that simply utilizes one single statistics for each attribute scores 95/150 accuracy. This shows that our method is able to provide a practical trade-off between accuracy and scalability.

\subsection{Neuroscience Dataset}
\subsubsection{Data Acquisition}
%The difficulty is especially pronounced in many scientific domains where there have been an increasing interest in nationwide and worldwide inter-institute collaboration. An example of such collaborative project is research in experimental event-related brain potential (ERP) analysis carried out at the NEMO (Neural Electromagnetic Ontologies) consortium laboratories. The heterogeneity among participating groups hinders meaningful meta-analysis despite the large number of studies in the field.

To address the problems of attribute and cluster matching in a real-world neuroscience application, we used a set of realistic simulated ERP (event-related potentials) datasets, which were designed to support evaluation of ERP analysis methods~\cite{FrishkoffEtal07}. The datasets were specifically designed to simulate heterogeneous data from different groups of subjects under different conditions (via distinct simulated brain activities), as well as distinct measurement methods (spatial and temporal metrics) and distinct patterns (reflecting two different pattern decomposition techniques). Real ERP data arise from superposition of latent scalp-surface electrophysiological patterns, each reflecting the activity of a distinct cortical network that cannot be reconstructed from the scalp-measured data with any certainty. Thus, real ERP data are not appropriate for evaluation of ERP pattern mapping. By contrast, simulated ERP data are derived from known source patterns and therefore provide the necessary gold standard for evaluation of our proposed methods.

The raw data for this study consist of 80 simulated event-related potentials (ERPs), in which each ERP comprises simulated measurement data for a particular subject ($n$ = 40). The 40 simulated subjects are randomly divided into two 20-subject groups, SG1 and SG2, each containing 40 ERPs (20 subjects in 2 experimental conditions). Each ERP consists of a superposition of 5 latent varying spatiotemporal patterns. These patterns were extracted from the two datasets, SG1 and SG2, using two techniques: temporal Principal Components Analysis (tPCA) and spatial Independent Components Analysis (sICA), two data decomposition techniques widely used in ERP research~\cite{Dien2010}. To quantify the spatiotemporal characteristics of the extracted patterns, two alternative metric sets, m1 and m2, were applied to the two tPCA and the two sICA derived datasets. For a complete explanation of these alternative metrics, please see Appendix in~\cite{FrishkoffEtal07}.

In summary, the simulated ERP data generation process yielded eight test datasets in total, reflecting a 2 (attribute sets) $\times$ 2 (subject groups) $\times$ 2 (decomposition methods) factorial design. Therefore, for each attribute set there are 4 datasets generated from different combinations of subject groups and decomposition methods, resulting $4 \times 4 = 16$ cases for the studies of attribute matching and cluster matching. The reason to include such variabilities was to test the robustness of our matching method to different sources of heterogeneities across the different datasets. Within all test datasets, 5 major ERP spatiotemporal patterns are present. They are P100, N100, N3, MFN, and P300. These patterns can be identified in the datasets by clustering analysis. Pretending that the latent patterns underlying discovered clusters are unknown, we hope to match clusters across datasets to recover the fact that the same patterns are present in all datasets.

\subsubsection{Results}
%Figure~\ref{fig:nemo_exp} illustrates the Pareto fronts derived by the proposed method on each of the 16 test cases.
We applied the weighted sum method as the post-processing step after obtaining the Pareto-optimal solutions to determine the most favored choice using the parameters ($\alpha$ and $\beta$) discovered in the preliminary experiments on synthetic datasets (cf. Section~\ref{sec:syn_exp}). The accuracy of attribute matching and cluster matching along with the number of points in the Pareto front are listed in Table~\ref{tbl:nemo_perf} (all these results are obtained by taking average from 5 runs for each test case).

%\begin{figure*}[tb]
%\begin{center}
%\includegraphics[width=1.\textwidth]{nemo_exp2.eps}
%\end{center}
%\caption{\label{fig:nemo_exp} Pareto fronts obtained from the 16 test cases of the neuroscience dataset.}
%\end{figure*}

It can be observed from the results in Table~\ref{tbl:nemo_perf} that more different factors involved in the acquisition of the two datasets for matching can negatively affect the matching performance. For example, in test case 1, the two datasets are drawn from the same subject group (SG1) and preprocessed using the same decomposition method (sICA); whereas in test case 4, the subject groups and decomposition methods are all different, resulting in greater variability and hence the performance is less satisfactory.

It is worth noticing that our method greatly outperforms a baseline method called WS (see Figure~\ref{fig:perf_comp}) that determines attribute matching based on data distribution at the whole attribute level, which is typical in previous systems such as SemInt~\cite{Li00semint:a}. In this figure we also demonstrate the accuracy of the segmented statistics characterization with expert-labeled patterns, meaning that the data is partitioned and aligned in the most accurate way, which marks the best achievable attribute matching performance. But it is not feasible because manually recognizing patterns (partitioning data) and aligning them across datasets requires a priori knowledge of attributes in the datasets which is exactly what the problem of attribute matching tries to discover (the circular causality problem). On the other hand, our method does not require human involvement (except the specification of the number of clusters (patterns) present in the data in order to run the clustering analysis) in determining both the attribute matching and cluster matching and is able to achieve close-to-optimal results.

\begin{figure*}[tb]
\begin{center}
\includegraphics[width=1.\textwidth]{fig/perf_comp.eps}
\end{center}
\caption[A comparison between methods on the neuroscience dataset]{\label{fig:perf_comp} A comparison of the attribute matching accuracy of three methods on the 16 test cases of the neuroscience dataset. The three methods being compared are matching based on whole-attribute statistics (WS), segmented attribute statistics without knowing a priori cluster matching (SS-u), and segmented attribute statistics with expert-aligned clusterings (SS).}
\end{figure*}


\begin{table*}[tbh]
\begin{center}
\begin{tabular}{l|l|l|l|l|l}
\hline
Test case & Source params & Target params & $~~~P_a~~~$ & $~~~P_c~~~$ & $|\Sigma|$\\
\hline
1		&	$\langle$	SG1, sICA, m1	$\rangle$	&	$\langle$	SG1, sICA, m2	$\rangle$	&		13/13	&	5/5	&	5	 \\
2		&	$\langle$	SG1, sICA, m1	$\rangle$	&	$\langle$	SG2, sICA, m2	$\rangle$	&		13/13	&	5/5	&	6	 \\
3		&	$\langle$	SG1, sICA, m1	$\rangle$	&	$\langle$	SG1, tPCA, m2	$\rangle$	&		10/13	&	5/5	&	6	 \\
4		&	$\langle$	SG1, sICA, m1	$\rangle$	&	$\langle$	SG2, tPCA, m2	$\rangle$	&		7/13	&	3/5	&	8	 \\
5		&	$\langle$	SG2, sICA, m1	$\rangle$	&	$\langle$	SG1, sICA, m2	$\rangle$	&		11/13	&	3/5	&	7	 \\
6		&	$\langle$	SG2, sICA, m1	$\rangle$	&	$\langle$	SG2, sICA, m2	$\rangle$	&		13/13	&	5/5	&	7	 \\
7		&	$\langle$	SG2, sICA, m1	$\rangle$	&	$\langle$	SG1, tPCA, m2	$\rangle$	&		10/13	&	5/5	&	6	 \\
8		&	$\langle$	SG2, sICA, m1	$\rangle$	&	$\langle$	SG2, tPCA, m2	$\rangle$	&		9/13	&	2/5	&	8	 \\
9		&	$\langle$	SG1, tPCA, m1	$\rangle$	&	$\langle$	SG1, sICA, m2	$\rangle$	&		7/13	&	5/5	&	4	 \\
10		&	$\langle$	SG1, tPCA, m1	$\rangle$	&	$\langle$	SG2, sICA, m2	$\rangle$	&		8/13	&	5/5	&	6	 \\
11		&	$\langle$	SG1, tPCA, m1	$\rangle$	&	$\langle$	SG1, tPCA, m2	$\rangle$	&		11/13	&	5/5	&	6	 \\
12		&	$\langle$	SG1, tPCA, m1	$\rangle$	&	$\langle$	SG2, tPCA, m2	$\rangle$	&		7/13	&	3/5	&	5	 \\
13		&	$\langle$	SG2, tPCA, m1	$\rangle$	&	$\langle$	SG1, sICA, m2	$\rangle$	&		7/13	&	3/5	&	5	 \\
14		&	$\langle$	SG2, tPCA, m1	$\rangle$	&	$\langle$	SG2, sICA, m2	$\rangle$	&		9/13	&	5/5	&	6	 \\
15		&	$\langle$	SG2, tPCA, m1	$\rangle$	&	$\langle$	SG1, tPCA, m2	$\rangle$	&		10/13	&	3/5	&	8	 \\
16		&	$\langle$	SG2, tPCA, m1	$\rangle$	&	$\langle$	SG2, tPCA, m2	$\rangle$	&		8/13	&	3/5	&	8	 \\
\hline
\end{tabular}
\end{center}
\caption[The performance of MOSA on the neuroscience dataset]{\label{tbl:nemo_perf} Matching performance of the proposed method with MOSA on the 16 test cases from the neuroscience dataset. The source and target parameter configuration of the data acquisition process of each test case are shown. $P_a$ and $P_c$ denote the accuracy of attribute matching and cluster matching respectively. $\Sigma$ is the number of points in the obtained Pareto-front. The quantities listed in the table are obtained by averaging over 5 runs of each test.}
\end{table*}

\subsection{Comparison with Multi-Objective Genetic Algorithm}
The concept of genetic algorithms (GA) was developed by Holland and his colleagues~\cite{Holland1992}. GA is first inspired by the evolutionary process in which weak and unfit species within their environment are faced with extinction and stronger ones have greater opportunities to pass their genes to next generation. Comparing to simulated annealing, GA often offers a different perspective in the field of numerical optimization. Starting from a number of random generated population and then performing cross over and evolve, GA has the ability to search in parallel around different and often fully scattered instances in the solution space, in contrast to the ``single thread" search in simulated annealing. We also implemented the Multi-Objective Genetic Algorithm (MOGA) developed by Fonseca \etal~\cite{Fonseca1993} as a metaheuristic to solve the dual matching problem.

%For the crossover operation in our MOGA implementation, we go through all the attributes (clusters) in a random sequence, if the matching of one attribute in both parents is not used, we keep the matching from either one of its parents with 50\% probability; if the matching of one of the two parent is used, we keep the matching from another parent; or if the matching of both parents are used already, we random choose one matching from the rest used matching attribute.

To compare the performance of GA and SA, we first carry out an experiment on the same set of neuroscience data, as shown in Table~\ref{tbl:moga_neuro}. The iteration parameters of both algorithms are tuned so that the convergence time are about the same. The performance are then compared under such setting. We manually examine the Pareto front derived in each test case and find the solution that is the closest to the gold standard and the accuracies are reported in Table~\ref{tbl:moga_neuro} (each number is averaged over 5 independent runs).

\begin{table*}[tbh]
\begin{center}
\begin{tabular}{l|l|l|l}
\hline
Test Case	&	$P_a$ (\%)	&	$P_c$ (\%) &   $\Sigma$    \\
\hline
1	&	100	&	100	  &   9\\
2	&	98.2	&	96.6	&   10\\
3	&	53.4	&	98.0	 &  9\\
4	&	53.3	&	98.0	&   11\\
5	&	100	&	98.2	&    5\\
6	&	71.2	&	96.0	&   6\\
7	&	59.4	&	94.4	&   6\\
8	&	59.7	&	98.8	&   6\\
9	&	25.2	&	100.0	&6 \\
10	&	38.5	&	100.0	& 5\\
11	&	77.7	&	99.2	&  7\\
12	&	69.2	&	100.0	& 9\\
13	&	38.7	&	100.0	& 9\\
14	&	40.3	&	98.8	&  11\\
15	&	45.0	&	96.0	&  8\\
16	&	84.6	&	98.8	&  16\\
\hline
\end{tabular}
\end{center}
\caption[The performance of MOGA on the neuroscience dataset]{\label{tbl:moga_neuro} Matching performance of the proposed method with MOGA on the 16 test cases from the neuroscience dataset. The source and target parameter configuration of each test case is the same as in Table~\ref{tbl:nemo_perf}.}
\end{table*}

The number of population kept in each generation is an important parameter regarding the complexity and performance in MOGA. Intuitively, the more instances we keep, the broader the search space we can explore in each generation. Table~\ref{tbl:moga_neuro} shows the result with the number of population set to 4. We have also tested other settings and found out that the accuracy in most cases increase with the number of population but in rare cases the performance deteriorates. The overall performance of MOGA is comparable to that of MOSA but appears to be less robust. It is worth noticing that the metaheuristics (MOSA and MOGA) we employed in the experiments are simple algorithms. More modern and sophisticated methods that explore various fitness assignment procedure, elitism, or diversification approaches will be very likely to improve the performance.


\begin{table*}[tbh]\footnotesize{
\begin{center}
\begin{tabular}{l|l|l|l|l|l|l}
\hline
\multicolumn{2}{c|}{}		&	fixed acidity	&	volatile acidity	&	citric acid	&	residual sugar	&	chlorides	\\
\hline
\multirow{2}{*}{mean}	&	data1	&	6.86	&	0.28	&	0.34	&	6.35	&	0.05	\\
	&	data2	&	6.85	&	0.28	&	0.33	&	6.43	&	0.05	\\
\hline
\multirow{2}{*}{stdev}	&	data1	&	0.84	&	0.1	&	0.12	&	4.98	&	0.02	\\
	&	data2	&	0.86	&	0.1	&	0.12	&	5.16	&	0.02	\\
\hline
\end{tabular}
\newline
\vspace*{.5cm}

\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
\multicolumn{2}{c|}{}		&	total sulfur dioxide	&	density	&	pH	&	sulphates	&	alcohol	&	quality	&	free sulfur dioxide	 \\
\hline
\multirow{2}{*}{mean}	&	data1	&	138.98	&	0.99	&	3.19	&	0.49	&	10.53	&	5.88	&	35.58	\\
	&	data2	&	137.68	&	0.99	&	3.19	&	0.49	&	10.49	&	5.88	&	35.02	\\
\hline
\multirow{2}{*}{stdev}	&	data1	&	41.86	&	0.02	&	0.16	&	0.11	&	1.25	&	0.89	&	16.4	\\
	&	data2	&	43.18	&	0	&	0.15	&	0.12	&	1.22	&	0.89	&	17.61	\\
\hline
\end{tabular}
\end{center}}
\caption[Distribution of the Wine Quality dataset]{\label{tbl:wine_stat} Summary of the statistical characteristics of attributes in the Wine Quality dataset.}
\end{table*}

\subsubsection{Wine Quality Dataset}
To further evaluate our method, we carried out another experiment on a real-world wine quality dataset~\cite{CorCer09} that is available through the UCI machine learning repository\footnote[1]{\url{http://archive.ics.uci.edu/ml/datasets/Wine+Quality}}. This dataset has 12 attributes and 4898 records. We apply uniform sampling to split it into two equal-sized subsets. The attributes are anonymized and randomly reordered in each subset to generate artificial heterogeneity.

We apply the proposed method with MOSA and MOGA as metaheuristics respectively. The test is focused on attribute matching because the gold standard is known while the gold standard of cluster matching is unknown. Table~\ref{tbl:wine_stat} summarizes the statistics for each attributes in the dataset. For both MOSA and MOGA derived Pareto optimal solutions, we manually select the one that is the closest to the gold-standard matching (e.g., the solution with 10 out 12 attributes matched correctly). Each metaheuristic is invoked 5 times and the matching accuracy is averaged over these runs. The performance for attribute matching is shown in Table~\ref{tbl:wine_res}. The result demonstrates a markedly high accuracy for both MOSA and MOGA. We notice that in most runs the Pareto fronts derived from MOSA and MOGA contain the gold standard matching (hence the high accuracy). It suggests a strategy to reduce the Pareto front in the matching problem by running MOSA or MOGA repeatedly after some times and only those ``stable" points that appear more than certain proportion of the times are considered to be presented to decision makers.

\begin{table*}[tbh]
\begin{center}
\begin{tabular}{l|l|l}
\hline
                &   MOSA    &   MOGA    \\
\hline
accuracy (\%)   &    95.5   &   92.3    \\
running time    &    517    &   3356    \\
\hline
\end{tabular}
\end{center}
\caption[The performance of MOSA and MOGA on the Wine Quality dataset]{\label{tbl:wine_res} Performance of the proposed method with MOSA and MOGA as metaheuristics respectively on the Wine Quality dataset.}
\end{table*}


\section{Discussion}
%\label{sec:discussion}
\textbf{Choices of the Data Representation Methods:}
Our choices of the methods to represent attributes and clusters are constrained by the specific challenges that are present in the matching problems.

Due to the nature of many scientific datasets, especially such as those in the neuroscience case study, our work on attribute matching is faced with following unique challenges. First, the data under study is semi-structured, thus invalidating those matching methods that presume a complete, known-in-advance schematic structure. In addition, totally different labels (usually acronyms or pseudowords) are widely adopted for the same or similar metrics, rendering lexical similarity-based methods unsuitable.

Moreover, an important limitation of previous instance-based matching methods is their inability to handle numerical instances. Only a handful number of existing methods have shown good performance on matching numeric attributes. iMAP~\cite{Dhamankar04imap} and SemInt~\cite{Li00semint:a} are two such methods; each of them has assumptions that make them unsuitable for our task in the neuroscience case study. The iMAP method requires the existence of joint paths between two tables through which data instances can be cross-referenced; however, two datasets can be drawn from different cohorts and therefore cannot be cross-referenced, because there are no overlapping instances. The SemInt method calculates statistics, such as maximum, minimum, mean, variance, \etc, of data content to characterize numeric attributes. The statistics are extracted by running aggregation queries against the whole set of attribute values. However, it is possible that two different attributes could have similar mean values, such as shown in the synthetic data case study; thus, SemInt statistics may be too coarse-grained to represent distinct ERP attributes.

Therefore, we choose to represent attributes using the segmented statistical characterization method to examine the grouping structure of attribute values, thus supporting fine-grained comparisons between attributes. As a result, we are able to calculate the straightforward Euclidean distance between attributes and to accurately capture the dissimilarity between them.

On the other hand, we have formulated the pattern matching problem motivated in the cross-lab collaborative ERP analysis as the cluster comparison problem. The cluster comparison problem is closely related to the cluster validity problem, such as the technique of external, or relative, indexing, which is used to compare different clustering results. Most previous methods based the comparison on evaluation of cluster membership (\cite{Rand71,Hamers1989,Fred03}). However, these methods are inappropriate for comparison of clustering results based on different datasets. Our motivation, in particular, is to find correspondences among ERP patterns from distinct datasets with non-overlapping observations (different study participants) in the neuroscience case study. For this reason, we examine methods that does not assume overlap in cluster membership across datasets.

We therefore choose to represent clusters as density profiles and use the ADCO clustering similarity index~\cite{Bae2010}) that is based on the density profile representation. The density profile representation does not assume common cluster membership and the ADCO measure can determine the similarity between two clusterings based on the distribution of data points along each attribute.

\textbf{Single Objective vs. Multi-objective Approaches:}
In the work reported in~\cite{LiuEtal10,LiuEtalNEUCOM12} we assume the cluster matching is known prior to the attribute matching. Then the attribute matching alone is simply a single objective problem. However, as we pointed out in the Introduction section, this is a gross simplification because attribute matching and cluster matching are intertwined and usually none can be known without the knowledge of the other. Therefore in this work, we focus on tackling this deadlock.

We argue that the single objective approach is not applicable given the way we represent attributes and clusters. Specifically, we represent an attribute as an ordered tuple, $<v_1, v_2, \ldots, v_3>$, where $v_i$ is some statistics of the attribute in a cluster $c_i$ of one dataset. Two attributes from different datasets can be compared only when we are able to arrange the tuples so that matching positions correspond to the same cluster. This assumes a certain kind of cluster matching. Vice versa, it is also true for cluster matching in that we need some input on attribute matching. Essentially the problem at hand is to search in two permutation spaces, one for each matching problem, which naturally leads to our multi-objective approach. If one was to adopt a single objective approach, the two spaces would have to be concatenated and variables aggregated by some functions (e.g., weighted sum).  We argue it might be flawed because there is no way to justify the ad hoc choice of such functions. On the contrary, the multi-objective approach based on Pareto optimality circumvents the choice of aggregation, but focuses on obtaining a non-dominating set of solutions (the Pareto set). We demonstrate in our case studies one simple way to utilize the Pareto set by combining both objectives based on weights that are determined through the pilot experiments. Note that applying weights before and after the optimization is fundamentally different. The former carries more systematic risk of missing true optimum due to the arbitrary choice of weights, while the latter is just one way to post-process the Pareto set that is very likely to contain the optimum. In practice, the Pareto set itself can be well treated as the final product of the matching analysis. Note that we show the sizes of Pareto sets in Table~\ref{tbl:nemo_perf} for the neuroscience test case, which are all reasonably small for examination to hand-pick best solutions.
 